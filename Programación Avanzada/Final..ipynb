{
  "metadata": {
    "name": "Final",
    "kernelspec": {
      "language": "scala",
      "name": "spark2-scala"
    },
    "language_info": {
      "codemirror_mode": "text/x-scala",
      "file_extension": ".scala",
      "mimetype": "text/x-scala",
      "name": "scala",
      "pygments_lexer": "scala"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# Análisis Exploratorio de Datos\n\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# Exploración de la data desde el archivo .csv"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "import org.apache.spark.sql.types._\n\nval mySchema \u003d StructType(\n    Array(\n        StructField(\"area\", IntegerType, false),\n        StructField(\"ciudad\", IntegerType, false),\n        StructField(\"conglomerado\", IntegerType, false),\n        StructField(\"panelm\", IntegerType, false),\n        StructField(\"vivienda\", IntegerType, false),\n        StructField(\"hogar\", IntegerType, false),\n        StructField(\"acceso_principal\", IntegerType, false),\n        StructField(\"tipo_vivienda\", IntegerType, false),\n        StructField(\"techo_material\", IntegerType, false),\n        StructField(\"estado_techo\", IntegerType, false),\n        StructField(\"piso_material\", IntegerType, false),\n        StructField(\"estado_piso\", IntegerType, false),\n        StructField(\"pared_material\", IntegerType, false),\n        StructField(\"estado_pared\", IntegerType, false),\n        StructField(\"nro_cuartos\", IntegerType, false),\n        StructField(\"nro_dormitorios\", IntegerType, false),\n        StructField(\"nro_cuartos_negocio\", IntegerType, false),\n        StructField(\"cocina_cuarto\", IntegerType, false),\n        StructField(\"cocinar_material\", IntegerType, false),\n        StructField(\"tipo_servicio_higienico\", IntegerType, false),\n        StructField(\"alternativa_no_higienico\", IntegerType, true),\n        StructField(\"tipo_instalacion_sanitaria\", IntegerType, true),\n        StructField(\"obtencion_agua\", IntegerType, false),\n        StructField(\"medidor_agua\", IntegerType, true),\n        StructField(\"junta_agua\", IntegerType, true),\n        StructField(\"tipo_tuberia\", IntegerType, false),\n        StructField(\"ducha\", IntegerType, false),\n        StructField(\"tipo_alumbrado\", StringType, false),\n        StructField(\"eliminacion_basura\", IntegerType, false),\n        StructField(\"tenencia_vivienda\", IntegerType, false),\n        StructField(\"valor_arriendo\", IntegerType, true),\n        StructField(\"inarriendo_agua\", IntegerType, true),\n        StructField(\"inarriendo_luz\", IntegerType, true),\n        StructField(\"parentesco_propietario\", IntegerType, true),\n        StructField(\"posesion_vehiculos\", IntegerType, false),\n        StructField(\"cantidad_vehiculos\", IntegerType, true),\n        StructField(\"posesion_motos\", IntegerType, true),\n        StructField(\"cantidad_motos\", IntegerType, true),\n        StructField(\"abastecimiento_super\", IntegerType, true),\n        StructField(\"gasto_super\", IntegerType, true),\n        StructField(\"abastecimiento_extra\", IntegerType, true),\n        StructField(\"gasto_extra\", IntegerType, true),\n        StructField(\"abastecimiento_diesel\", IntegerType, true),\n        StructField(\"gasto_diesel\", IntegerType, true),\n        StructField(\"abastecimiento_eco\", IntegerType, true),\n        StructField(\"gasto_eco\", IntegerType, true),\n        StructField(\"abastecimiento_elect\", IntegerType, true),\n        StructField(\"gasto_elect\", IntegerType, true),\n        StructField(\"abastecimiento_gas\", IntegerType, true),\n        StructField(\"gasto_gas\", IntegerType, true),\n        StructField(\"estrato\", IntegerType, false),\n        StructField(\"fexp\", StringType, false),\n        StructField(\"upm\", StringType, false),\n        StructField(\"id_vivienda\", StringType, false),\n        StructField(\"id_hogar\", StringType, false),\n        StructField(\"periodo\", IntegerType, false),\n        StructField(\"mes\", StringType, false)\n        ));\n"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val data \u003d spark\n    .read\n    .schema(mySchema)\n    .option(\"header\", \"true\")\n    .option(\"delimiter\", \";\")\n    .csv(\"/workspace/zeppelin-paavanzada/enemdu_vivienda_hogar_2023_I_trimestre.csv\")"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Columnas Cuantitativas"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### Columna Valor Arriendo\nEsta columna posee los valores que las personas pagan o pagarían por el arriendo de su hogar"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "data.select(\"valor_arriendo\").summary().show()"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val dfArriendoUnic \u003d data.select(\"valor_arriendo\").groupBy(\"valor_arriendo\").count\n\ndfArriendoUnic.count\n\nz.show(dfArriendoUnic)"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "import org.apache.spark.sql.types._\n\nval avg \u003d data.select(mean(\"valor_arriendo\"))\n\t\t.first()(0)//fila 0 columna 0\n\t\t.asInstanceOf[Double]"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "\nval stdDesv \u003d data.select(stddev(\"valor_arriendo\"))\n\t\t.first()(0)//fila 0 columna 0\n\t\t.asInstanceOf[Double]//Traelo como instacia de tipo Double\n\t\t\n\t\t"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val inferior \u003d avg - 3 * stdDesv //Si es negativo no tendremos ningun valor\nval superior \u003d avg + 3 * stdDesv"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val valoresMenoresInferior \u003d  data.select(\"valor_arriendo\").where($\"valor_arriendo\" \u003c inferior)\nvaloresMenoresInferior.describe().show"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val valoresMayoresSuperior \u003d data.select($\"valor_arriendo\").where($\"valor_arriendo\" \u003e superior)\nvaloresMayoresSuperior.describe().show"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val arriendoSinOutliers \u003d data.select(\"valor_arriendo\").where($\"valor_arriendo\" \u003c superior)\n\narriendoSinOutliers.summary().show()"
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val dataSinOutliersUnic \u003d arriendoSinOutliers.select(\"valor_arriendo\").groupBy(\"valor_arriendo\").count\n\ndataSinOutliersUnic.count"
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "\n\n\n//Colocar Dataframe sin Ouliers y solo con Valores Únicos \n//en el contexto para luego convertirlo a dataframe en Pyspark\n\nz.put(\"dfSinOutliers\", dataSinOutliersUnic)\n"
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nfrom pyspark.sql import DataFrame\nfrom pyspark.sql.functions import col\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport scipy.stats as stats\n\n# Obtener el DataFrame de dfCuantitativo\ndfValorArriendo \u003d DataFrame(z.get(\"dfSinOutliers\"), sqlContext)\n\n# Convertir la columna \"valor_arriendo\" a tipo Double\ndfValorArriendo \u003d dfValorArriendo.withColumn(\"valor_arriendo\", col(\"valor_arriendo\").cast(\"double\"))\n\n# Obtener los datos como una lista\nvalor_arriendo_data \u003d dfValorArriendo.select(\"valor_arriendo\").rdd.flatMap(lambda x: x).collect()\n\n# Ordenar los datos de menor a mayor\nvalor_arriendo_data_sorted \u003d sorted(valor_arriendo_data)\n\n# Convertir los datos a un array de numpy\nvalor_arriendo_array \u003d np.array(valor_arriendo_data_sorted)\n\n# Crear el QQ plot con los datos \nplt.figure(figsize\u003d(10, 8))\nstats.probplot(valor_arriendo_array, plot\u003dplt, dist\u003d\u0027norm\u0027)\n\nplt.title(\u0027QQ Plot de valor_arriendo\u0027)\nplt.xlabel(\u0027Cuantiles teóricos\u0027)\nplt.ylabel(\u0027Valores de arriendo\u0027)\nplt.show()\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Columnas de Texto"
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "\nval dfCualitativo \u003d data.select(\"area\",\n\"ciudad\", \n\"tipo_vivienda\", \n\"techo_material\", \n\"estado_techo\", \n\"piso_material\",\n\"estado_piso\",\n\"pared_material\",\n\"estado_pared\",\n\"tipo_servicio_higienico\",\n\"alternativa_no_higienico\",\n\"tipo_instalacion_sanitaria\",\n\"tipo_tuberia\",\n\"tenencia_vivienda\",\n\"valor_arriendo\",\n\"parentesco_propietario\")"
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "print(dfCualitativo.select(\"area\")\n            .distinct()\n            .count() + \"\\n\")\ndata.groupBy(\"area\")\n    .count()\n    .sort(\"area\")\n    .show()\n"
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "// Definir una función para realizar el reemplazo de valores en la columna \"area\"\nval reemplazarArea \u003d udf((valor: Int) \u003d\u003e valor match {\n  case 1 \u003d\u003e \"Urbana\"\n  case 2 \u003d\u003e \"Rural\"\n})\n\n// Crear una nueva columna \"area_etiqueta\" con los valores reemplazados\nval data_with_etiquetas \u003d dfCualitativo.withColumn(\"area\", reemplazarArea(col(\"area\")))\n\n// Agrupar y contar por \"area_etiqueta\"\ndata_with_etiquetas.groupBy(\"area\").count().sort(\"area\").show()"
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "print(data.select(\"tipo_vivienda\")\n            .distinct()\n            .count() + \"\\n\")\n\ndata.groupBy(\"tipo_vivienda\")\n    .count()\n    .sort(desc(\"count\"))\n    .show() "
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "// Definir una función para realizar el reemplazo de valores\r\nval reemplazarTipoVivienda \u003d udf((valor: Int) \u003d\u003e valor match {\r\n  case 1 \u003d\u003e \"Casa_o_villa\"\r\n  case 2 \u003d\u003e \"Departamento\"\r\n  case 3 \u003d\u003e \"Cuartos_en_casa_de_inquilinato\"\r\n  case 4 \u003d\u003e \"Mediagua\"\r\n  case 5 \u003d\u003e \"Rancho, covacha\"\r\n  case 6 \u003d\u003e \"Choza\"\r\n  case 7 \u003d\u003e \"Otra\"\r\n})\r\n\r\n// Agrupar y contar por \"tipo_vivienda\"\r\ndata_with_etiquetas.groupBy(\"tipo_vivienda\").count().sort(\"tipo_vivienda\").show()"
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "// Definir una función para realizar el reemplazo de valores en la columna \"techo_material\"\nval reemplazarTechoMaterial \u003d udf((valor: Int) \u003d\u003e valor match {\n  case 1 \u003d\u003e \"Hormigón (losa, cemento)\"\n  case 2 \u003d\u003e \"Fibrocemento, asbesto (eternit, eurolit)\"\n  case 3 \u003d\u003e \"Zinc, Aluminio\"\n  case 4 \u003d\u003e \"Teja\"\n  case 5 \u003d\u003e \"Palma, paja u hoja\"\n  case 6 \u003d\u003e \"Otro Material\"\n})\n\n\n// Agrupar y contar por \"techo_material_etiqueta\"\ndata_with_etiquetas.groupBy(\"techo_material\").count().sort(\"techo_material\").show()"
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "// Definir una función para realizar el reemplazo de valores en las columnas\nval reemplazarEstadoTecho \u003d udf((valor: Int) \u003d\u003e valor match {\n  case 1 \u003d\u003e \"Bueno\"\n  case 2 \u003d\u003e \"Regular\"\n  case 3 \u003d\u003e \"Malo\"\n\n})\n\nval reemplazarPisoMaterial \u003d udf((valor: Int) \u003d\u003e valor match {\n  case 1 \u003d\u003e \"Duela, parquet, tablón tratado o piso flotante\"\n  case 2 \u003d\u003e \"Cerámica, baldosa, vinil o porcelanato \"\n  case 3 \u003d\u003e \"Mármol o marmetón\"\n  case 4 \u003d\u003e \"Ladrillo o cemento\"\n  case 5\u003d\u003e \"Tabla / tablón no tratado\"\n  case 6\u003d\u003e \"Caña\"\n  case 7 \u003d\u003e \"Tierra\"\n  case 8\u003d\u003e \"Otro Material\"\n})\n\nval reemplazarEstadoPiso \u003d udf((valor: Int) \u003d\u003e valor match {\n  case 1 \u003d\u003e \"Bueno\"\n  case 2 \u003d\u003e \"Regular\"\n  case 3 \u003d\u003e \"Malo\"\n \n})\n\nval reemplazarParedMaterial \u003d udf((valor: Int) \u003d\u003e valor match {\n  case 1 \u003d\u003e \"Hormigón/Ladrillo o Bloque\"\n  case 2 \u003d\u003e \"Asbesto/Cemento (Fibrolit)\"\n  case 3 \u003d\u003e \"Adobe o Tapia\"\n  case 4 \u003d\u003e \"Madera\"\n  case 5 \u003d\u003e \"Caña revestida o bahareque\"\n  case 6 \u003d\u003e \"Caña no revestida o estera\"\n  case 7 \u003d\u003e \"Otra Material\"\n\n})\n\nval reemplazarEstadoPared \u003d udf((valor: Int) \u003d\u003e valor match {\n  case 1 \u003d\u003e \"Bueno\"\n  case 2 \u003d\u003e \"Regular\"\n  case 3 \u003d\u003e \"Malo\"\n\n})\n\n\n// Definir una función para realizar el reemplazo de valores en la columna \"tipo_servicio_higienico\"\nval reemplazarTipoServicioHigienico \u003d udf((valor: Int) \u003d\u003e valor match {\n  case 1 \u003d\u003e \"Excusado y alcantarillado\"\n  case 2 \u003d\u003e \"Excusado y pozo séptico\"\n  case 3 \u003d\u003e \"Excusado y pozo ciego\"\n  case 4 \u003d\u003e \"Letrina\"\n  case 5 \u003d\u003e \"No tiene\"\n \n})\n\n// Definir una función para realizar el reemplazo de valores en la columna \"alternativa_no_higienico\"\nval reemplazarAlternativaNoHigienico \u003d udf((valor: Int) \u003d\u003e valor match {\n  case 1 \u003d\u003e \"Descarga directa al mar, río, lago o quebrada\"\n  case 2 \u003d\u003e \"Van al monte, campo, bota la basura en paquete\"\n  case 3 \u003d\u003e \"Usan una instalación sanitaria cercana y/o prestada\"\n \n})\n\n\n// Definir una función para realizar el reemplazo de valores en la columna \"tipo_instalacion_sanitaria\"\nval reemplazarTipoInstalacionSanitaria \u003d udf((valor: Int) \u003d\u003e valor match {\n  case 1 \u003d\u003e \"Excusado y alcantarillado\"\n  case 2 \u003d\u003e \"Excusado y pozo séptico\"\n  case 3 \u003d\u003e \"Excusado y pozo ciego\"\n  case 4 \u003d\u003e \"Letrina\"\n \n})\n\n// Definir una función para realizar el reemplazo de valores en la columna \"tenencia_vivienda\"\nval reemplazarTenenciaVivienda \u003d udf((valor: Int) \u003d\u003e valor match {\n  case 1 \u003d\u003e \"En arriendo\"\n  case 2 \u003d\u003e \"Anticresis y/o arriendo\"\n  case 3 \u003d\u003e \"Propia y la está pagando\"\n  case 4 \u003d\u003e \"Propia y totalmente pagada\"\n  case 5 \u003d\u003e \"Cedida\"\n  case 6 \u003d\u003e \"Recibida por servicios\"\n  case 7 \u003d\u003e \"Otra\"\n  \n})\n\n// Definir una función para realizar el reemplazo de valores en la columna \"tipo_tuberia\"\nval reemplazarTipoTuberia \u003d udf((valor: Int) \u003d\u003e valor match {\n  case 1 \u003d\u003e \"Por tubería dentro de la vivienda\"\n  case 2 \u003d\u003e \"Por tubería fuera de la vivienda pero en el lote\"\n  case 3 \u003d\u003e \"Por tubería fuera de la vivienda, lote o terreno\"\n  case 4 \u003d\u003e \"No recibe agua por tubería sino por otros medios\"\n \n})\nval reemplazarParentescoPropietario \u003d udf((valor: Int) \u003d\u003e valor match {\n  case 1 \u003d\u003e \"Si\"\n  case 2 \u003d\u003e \"NO\"\n})\n"
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "\n// Crear un nuevo dataFrame con las columnas que han sido cambiadas\nval data_with_etiquetas \u003d dfCualitativo\n  .withColumn(\"area\", reemplazarArea(col(\"area\")))\n  .withColumn(\"tipo_vivienda\", reemplazarTipoVivienda(col(\"tipo_vivienda\")).cast(StringType))\n  .withColumn(\"techo_material\", reemplazarTechoMaterial(col(\"techo_material\")).cast(StringType))\n  .withColumn(\"estado_techo\", reemplazarEstadoTecho(col(\"estado_techo\")).cast(StringType))\n  .withColumn(\"piso_material\", reemplazarPisoMaterial(col(\"piso_material\")).cast(StringType))\n  .withColumn(\"estado_piso\", reemplazarEstadoPiso(col(\"estado_piso\")).cast(StringType))\n  .withColumn(\"pared_material\", reemplazarParedMaterial(col(\"pared_material\")).cast(StringType))\n  .withColumn(\"estado_pared\", reemplazarEstadoPared(col(\"estado_pared\")).cast(StringType))\n   .withColumn(\"tipo_servicio_higienico\", reemplazarTipoServicioHigienico(col(\"tipo_servicio_higienico\")).cast(StringType))\n  .withColumn(\"alternativa_no_higienico\", reemplazarAlternativaNoHigienico(col(\"alternativa_no_higienico\")).cast(StringType))\n  .withColumn(\"tipo_instalacion_sanitaria\", reemplazarTipoInstalacionSanitaria(col(\"tipo_instalacion_sanitaria\")).cast(StringType))\n  .withColumn(\"tenencia_vivienda\", reemplazarTenenciaVivienda(col(\"tenencia_vivienda\")).cast(StringType))\n  .withColumn(\"tipo_tuberia\", reemplazarTipoTuberia(col(\"tipo_tuberia\")).cast(StringType))\n .withColumn(\"parentesco_propietario \",reemplazarParentescoPropietario(col(\"parentesco_propietario\")).cast(StringType))\n"
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "data_with_etiquetas.printSchema"
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "data_with_etiquetas.groupBy(\"tipo_instalacion_sanitaria\").count().sort(\"tipo_instalacion_sanitaria\").show()\r\ndata_with_etiquetas.groupBy(\"tenencia_vivienda\").count().sort(\"tenencia_vivienda\").show()\r\ndata_with_etiquetas.groupBy(\"tipo_tuberia\").count().sort(\"tipo_tuberia\").show()\r\ndata_with_etiquetas.groupBy(\"tipo_servicio_higienico\").count().sort(\"tipo_servicio_higienico\").show()\r\ndata_with_etiquetas.groupBy(\"alternativa_no_higienico\").count().sort(\"alternativa_no_higienico\").show()\r\ndata_with_etiquetas.groupBy(\"estado_techo\").count().sort(\"estado_techo\").show()\r\ndata_with_etiquetas.groupBy(\"piso_material\").count().sort(\"piso_material\").show()\r\ndata_with_etiquetas.groupBy(\"estado_piso\").count().sort(\"estado_piso\").show()\r\ndata_with_etiquetas.groupBy(\"pared_material\").count().sort(\"pared_material\").show()\r\ndata_with_etiquetas.groupBy(\"estado_pared\").count().sort(\"estado_pared\").show()"
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val viviendasPorTipo \u003d data_with_etiquetas.groupBy(\"tipo_vivienda\").count().sort(desc(\"count\"))\n\n\n// Mostrar la cantidad de viviendas por tipo de vivienda\nviviendasPorTipo.show()\n\nz.show(viviendasPorTipo)"
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val dfFiltradoTipoVivienda \u003d data_with_etiquetas.filter($\"tipo_vivienda\" \u003d\u003d\u003d \"Departamento\")\r\n\r\n// Filtrar por estado del techo \"Regular\"\r\nval dfFiltradoEstadoTecho \u003d data_with_etiquetas.filter($\"estado_techo\" \u003d\u003d\u003d \"Regular\")\r\n\r\n// Filtrar por tipo de vivienda \"Departamento\" y estado del techo \"Regular\"\r\nval dfFiltrado \u003d data_with_etiquetas.filter($\"tipo_vivienda\" \u003d\u003d\u003d \"Departamento\" \u0026\u0026 $\"estado_techo\" \u003d\u003d\u003d \"Regular\")\r\n\r\ndfFiltrado.count()\r\n\r\nz.show(dfFiltrado)"
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "import org.apache.spark.sql.functions\r\n\r\n// Convertir la columna \"valor_arriendo\" a tipo Double\r\nval dfConValorArriendo \u003d data_with_etiquetas.withColumn(\"valor_arriendo\", $\"valor_arriendo\".cast(\"Double\"))\r\n\r\n// Calcular el promedio del valor arriendo por tipo de vivienda\r\nval promedioArriendoPorTipo \u003d dfConValorArriendo.groupBy(\"tipo_vivienda\")\r\n  .agg(functions.avg($\"valor_arriendo\").alias(\"promedio_arriendo\"))\r\n  .sort(desc(\"promedio_arriendo\"))\r\n\r\n// Mostrar el resultado\r\npromedioArriendoPorTipo.show()\r\n\r\n"
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val viviendasPorTipo \u003d data_with_etiquetas.filter($\"area\" \u003d\u003d\u003d \"Urbana\")\r\n  .groupBy(\"tipo_vivienda\")\r\n  .count()\r\n  .sort(desc(\"count\"))\r\nz.show(viviendasPorTipo)"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Gráficas realizadas con Conexión a la Base de Datos"
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%mySQL(saveAs\u003dconsulAngular01)\n\nSELECT subq.nombre_provincia, subq.tipo_vivienda, subq.promedio_arriendo\nFROM (\n    SELECT p.nombre_provincia, v.tipo_vivienda, AVG(h.valor_arriendo) AS promedio_arriendo, p.tasa_desempleo\n    FROM provincia p\n    JOIN canton c ON p.cod_provincia \u003d c.provincia_canton\n    JOIN parroquia pa ON c.cod_canton \u003d pa.cod_canton\n    JOIN vivienda v ON pa.cod_parroquia \u003d v.cod_parroquia\n    JOIN hogar h ON v.id_vivienda \u003d h.id_vivienda\n    GROUP BY p.nombre_provincia, v.tipo_vivienda, p.tasa_desempleo\n) AS subq\nWHERE subq.tasa_desempleo \u003c (SELECT AVG(tasa_desempleo) FROM provincia)\nORDER BY subq.nombre_provincia DESC;\n"
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val dfFromMysqlAng \u003d z.get(\"consulAngular01\")\n\nval arr \u003d dfFromMysqlAng.toString.split(\"\\n\")\nval colsName \u003d arr(0).split(\"\\t\")\nval dataArr \u003d arr.drop(1)\nval data \u003d dataArr.map(row\u003d\u003e row.split(\"\\t\")).map(row\u003d\u003e (row(0), row(1), row(2).toDouble))\n\nval dfAux \u003d spark\n .createDataFrame(data)\n .toDF(colsName(0), colsName(1), colsName(2))"
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val auxDF \u003d dfAux.groupBy(\"nombre_provincia\").pivot(\"tipo_vivienda\").avg(\"promedio_arriendo\").orderBy(\"nombre_provincia\").na.fill(0)\nauxDF.show"
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val json \u003d auxDF.toJSON.map(row \u003d\u003e row.mkString).collectAsList\n\nz.angularBind(\"dataAsJSON\", json)"
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%angular\r\n\u003cinput type\u003d\"text\" id\u003d\"data4Spark\" value\u003d{{dataAsJSON}}\u003e"
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "\n%angular\n\u003cscript\u003e\nvar cleanText \u003d $(\u0027#data4Spark\u0027).val().replaceAll(\"\\\\\", \"\").replaceAll(\"\\\"{\", \"{\").replaceAll(\"}\\\"\",\n\"}\");\nconsole.log(cleanText);\n$(\u0027#data4Spark\u0027).val(cleanText);\n\u003c/script\u003e"
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%angular\n\u003cstyle\u003e\n#chartdiv {\n    width: 100%;\n    height: 500px;\n}\n\u003c/style\u003e\n\n\u003c!-- Resources --\u003e\n\u003cscript src\u003d\"https://cdn.amcharts.com/lib/5/index.js\"\u003e\u003c/script\u003e\n\u003cscript src\u003d\"https://cdn.amcharts.com/lib/5/xy.js\"\u003e\u003c/script\u003e\n\u003cscript src\u003d\"https://cdn.amcharts.com/lib/5/themes/Animated.js\"\u003e\u003c/script\u003e\n\n\u003c!-- Chart code --\u003e\n\u003cscript\u003e\n\n// Leer los datos desde el input (No necesita cambio) y transformarlos a JSON\nvar data \u003d JSON.parse($(\u0027#data4Spark\u0027).val());\nconsole.log(data);\nam5.ready(function() {\n// Create root element\n// https://www.amcharts.com/docs/v5/getting-started/#Root_element\nvar root \u003d am5.Root.new(\"chartdiv\");\n// Set themes\n// https://www.amcharts.com/docs/v5/concepts/themes/\nroot.setThemes([\nam5themes_Animated.new(root)\n]);\n// Create chart\n// https://www.amcharts.com/docs/v5/charts/xy-chart/\nvar chart \u003d root.container.children.push(am5xy.XYChart.new(root, {\npanX: false,\npanY: false,\nwheelX: \"panX\",\nwheelY: \"zoomX\",\nlayout: root.verticalLayout\n}));\n// Add legend\n// https://www.amcharts.com/docs/v5/charts/xy-chart/legend-xy-series/\nvar legend \u003d chart.children.push(\nam5.Legend.new(root, {\ncenterX: am5.p50,\nx: am5.p50,\nposition: \u0027top\u0027\n})\n);\n// Create axes\n// https://www.amcharts.com/docs/v5/charts/xy-chart/axes/\nvar xRenderer \u003d am5xy.AxisRendererX.new(root, {\ncellStartLocation: 0.1,\ncellEndLocation: 0.9\n})\nvar xAxis \u003d chart.xAxes.push(am5xy.CategoryAxis.new(root, {\ncategoryField: \"nombre_provincia\", //Cambiar por su columna de agrupamiento\nrenderer: xRenderer,\ntooltip: am5.Tooltip.new(root, {})\n}));\nxRenderer.grid.template.setAll({\nlocation: 1\n})\nxAxis.data.setAll(data);\nvar yAxis \u003d chart.yAxes.push(am5xy.ValueAxis.new(root, {\nrenderer: am5xy.AxisRendererY.new(root, {\nstrokeOpacity: 0.1\n})\n}));\n// Add series\n// https://www.amcharts.com/docs/v5/charts/xy-chart/series/\nfunction makeSeries(name, fieldName) {\nvar series \u003d chart.series.push(am5xy.ColumnSeries.new(root, {\nname: name,\nxAxis: xAxis,\nyAxis: yAxis,\nvalueYField: fieldName,\ncategoryXField: \"nombre_provincia\" //Cambiar por su columna de agrupamiento\n}));\nseries.columns.template.setAll({\ntooltipText: \"{name}, {categoryX}:{valueY.formatNumber(\u0027###.##\u0027)}\",\nwidth: am5.percent(90),\ntooltipY: 0,\nstrokeOpacity: 0\n});\nseries.data.setAll(data);\n// Make stuff animate on load\n// https://www.amcharts.com/docs/v5/concepts/animations/\nseries.appear();\nseries.bullets.push(function() {\nreturn am5.Bullet.new(root, {\nlocationY: 0,\nsprite: am5.Label.new(root, {\ntext: \"{valueY}\",\nfill: root.interfaceColors.get(\"alternativeText\"),\ncenterY: 0,\ncenterX: am5.p50,\npopulateText: true\n})\n});\n});\nlegend.data.push(series);\n}\n//Necesita adaptar para el resto de sus columnas, una llamada a makeSeries por cada columna\n//En makeSeries, el primer parámetro es el valor a mostrar y el segundo es el nombre de\n//la columna o propiedad JSON\nmakeSeries(\"Casa o Villa\", \"Casa o Villa\");\nmakeSeries(\"Choz\", \"Choza\");\nmakeSeries(\"Cuartos en casa de inquilinato\", \"Cuartos en casa de inquilinato\");\nmakeSeries(\"Departamento\", \"Departamento\");\nmakeSeries(\"Mediagua\", \"Mediagua\");\nmakeSeries(\"Rancho\", \"Rancho, covacha\");\n// Make stuff animate on load\n//https://www.amcharts.com/docs/v5/concepts/animations/\nchart.appear(1000, 100);\n}); // end am5.ready()\n\u003c/script\u003e\n\u003c!-- HTML --\u003e\n\u003cdiv id\u003d\"chartdiv\"\u003e\u003c/div\u003e"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": " \n\n### Consulta Cristian Rodriguez"
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%mySQL\nSELECT\n    v.tipo_vivienda,\n    h.material_piso,\n    COUNT(v.id_vivienda) AS nros_vivienda\nFROM\n    vivienda v\nJOIN\n    hogar h ON v.id_vivienda \u003d h.id_vivienda\nGROUP BY\n    v.tipo_vivienda, h.material_piso;"
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%mySQL\nSELECT\n    v.tipo_vivienda,\n    h.material_paredes,\n    COUNT(v.id_vivienda) AS nros_vivienda\nFROM\n    vivienda v\nJOIN\n    hogar h ON v.id_vivienda \u003d h.id_vivienda\nGROUP BY\n    v.tipo_vivienda, h.material_paredes;"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### Proporción del estado del hogar según el material\n\nEstado de paredes, piso y techo según su material"
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val query \u003d \"\"\"\n    (SELECT estado_techo, estado_piso, estado_paredes, material_piso, material_techo, material_paredes\n     FROM hogar) as qryData\n    \"\"\"\n    \nval tempDF \u003d spark.read\n    .format(\"jdbc\")\n    .option(\"url\", \"jdbc:mysql://localhost:3306/mydb_integrador\") //\"jdbc:mysql://hostname:port/dbname\"\n    .option(\"driver\", \"com.mysql.jdbc.Driver\")\n    .option(\"user\", \"root\")\n    .option(\"password\", \"\")\n    .option(\"dbtable\", query)\n    .load()\n"
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "z.show(tempDF.limit(5))"
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val df_techos\u003d tempDF.groupBy(\"estado_techo\", \"material_techo\").count()"
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "z.show(df_techos)"
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "///DF para Techos\r\nval df_techos\u003d tempDF.groupBy(\"estado_techo\", \r\n                              \"material_techo\").count()\r\n                              \r\n//Df para Paredes\r\nval df_paredes\u003d tempDF.groupBy(\"estado_paredes\", \r\n                              \"material_paredes\").count()\r\n                              \r\n//DF para Piso\r\nval df_piso\u003d tempDF.groupBy(\"estado_piso\", \r\n                              \"material_piso\").count()\r\n"
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "import org.apache.spark.sql.functions._\r\nimport org.apache.spark.sql.expressions.Window\r\n\r\nval df_groupedwTotal \u003d df_techos.withColumn(\r\n    \"total\", \r\n    sum(\"count\").over(Window.partitionBy(\"material_techo\")))\r\n\r\nval df_groupedwProportion \u003d df_groupedwTotal.withColumn(\r\n    \"proportion\", \r\n    col(\"count\") / col(\"total\"))\r\n\r\n\r\nval df_groupedwTotalParedes \u003d df_paredes.withColumn(\r\n    \"total\", \r\n    sum(\"count\").over(Window.partitionBy(\"material_paredes\")))\r\n\r\nval df_groupedwProportionParedes \u003d df_groupedwTotalParedes.withColumn(\r\n    \"proportion\", \r\n    col(\"count\") / col(\"total\"))\r\n    \r\n\r\nval df_groupedwTotalPiso \u003d df_piso.withColumn(\r\n    \"total\", \r\n    sum(\"count\").over(Window.partitionBy(\"material_piso\")))\r\n\r\nval df_groupedwProportionPiso \u003d df_groupedwTotalPiso.withColumn(\r\n    \"proportion\", \r\n    col(\"count\") / col(\"total\"))\r\n"
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "z.show(df_groupedwProportion)"
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "z.put(\"df_grouped_correlation\", df_groupedwProportion)\nz.put(\"df_grouped_paredes\", df_groupedwProportionParedes)\nz.put(\"df_grouped_piso\", df_groupedwProportionPiso)\n"
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nfrom pyspark.sql import DataFrame\nimport pandas as pd\n\ndftecho \u003d DataFrame(z.get(\"df_grouped_correlation\"), sqlContext)\npdftecho \u003d dftecho.toPandas()\n\ndfpared \u003d DataFrame(z.get(\"df_grouped_paredes\"), sqlContext)\npdfpared \u003d dfpared.toPandas()\n\ndfpiso \u003d DataFrame(z.get(\"df_grouped_piso\"), sqlContext)\npdfpiso \u003d dfpiso.toPandas()\n\n"
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\r\nimport numpy as np\r\nimport matplotlib.pyplot as plt\r\n\r\n# Crear un gráfico de barras agrupadas con tamaño más grande\r\nfig, ax \u003d plt.subplots(figsize\u003d(12, 8))  # Ajustar el tamaño aquí\r\n\r\n# Lista de estados del techo y materiales únicos\r\nestados_techo \u003d pdftecho[\u0027estado_techo\u0027].unique()\r\nmateriales_techo \u003d pdftecho[\u0027material_techo\u0027].unique()\r\n\r\n# Diccionario para asignar colores a cada estado del techo\r\ncolores_dict \u003d {\r\n    \u0027Malo\u0027: \u0027r\u0027,      # Rojo\r\n    \u0027Regular\u0027: \u0027c\u0027,   # Amarillo\r\n    \u0027Bueno\u0027: \u0027g\u0027      # Verde\r\n}\r\n\r\n# Ancho de las barras agrupadas\r\nbar_width \u003d 0.2\r\n\r\n# Posiciones para cada grupo de barras\r\npositions \u003d np.arange(len(materiales_techo))\r\n\r\n# Crear las barras agrupadas y agregar etiquetas\r\nfor i, estado_techo in enumerate(estados_techo):\r\n    estado_color \u003d colores_dict.get(estado_techo, \u0027k\u0027)\r\n    data_estado \u003d pdftecho[pdftecho[\u0027estado_techo\u0027] \u003d\u003d estado_techo][\u0027proportion\u0027]\r\n    ax.bar(\r\n        positions + i * bar_width, \r\n        data_estado, \r\n        bar_width, \r\n        label\u003destado_techo, \r\n        color\u003destado_color\r\n    )\r\n\r\n    # Agregar etiquetas a las barras\r\n    for j in range(len(materiales_techo)):\r\n        ax.text(\r\n            positions[j] + i * bar_width, \r\n            data_estado.iloc[j] + 0.01, \r\n            f\"{data_estado.iloc[j]:.2f}\", \r\n            ha\u003d\u0027center\u0027\r\n        )\r\n\r\n# Añadir la leyenda, etiquetas de eje y título\r\nax.legend(title\u003d\u0027Estado del techo\u0027)\r\nplt.xlabel(\u0027Material del techo\u0027)\r\nplt.ylabel(\u0027Proporción\u0027)\r\nplt.title(\u0027Proporción de estado del techo por material\u0027)\r\n\r\n# Posiciones del eje x y etiquetas para cada barra agrupada\r\nax.set_xticks(positions + (bar_width * len(estados_techo) / 2))\r\nax.set_xticklabels(materiales_techo)\r\n\r\n# Rotar las etiquetas del eje x\r\nplt.xticks(rotation\u003d-45)\r\n\r\n# Mostrar el gráfico\r\nplt.tight_layout()\r\nplt.show()\r\n"
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Crear un gráfico de barras agrupadas con tamaño más grande\nfig, ax \u003d plt.subplots(figsize\u003d(12, 8))  # Ajustar el tamaño aquí\n\n# Lista de estados del techo y materiales únicos\nestados_pared \u003d pdfpared[\u0027estado_paredes\u0027].unique()\nmateriales_pared \u003d pdfpared[\u0027material_paredes\u0027].unique()\n\n# Diccionario para asignar colores a cada estado del techo\ncolores_dict \u003d {\n    \u0027Malo\u0027: \u0027r\u0027,      # Rojo\n    \u0027Regular\u0027: \u0027c\u0027,   # Amarillo\n    \u0027Bueno\u0027: \u0027g\u0027      # Verde\n}\n\n# Ancho de las barras agrupadas\nbar_width \u003d 0.2\n\n# Posiciones para cada grupo de barras\npositions \u003d np.arange(len(materiales_pared))\n\n# Crear las barras agrupadas y agregar etiquetas\nfor i, estado_pared in enumerate(estados_pared):\n    estado_color \u003d colores_dict.get(estado_pared, \u0027k\u0027)\n    data_estado \u003d pdfpared[pdfpared[\u0027estado_paredes\u0027] \u003d\u003d estado_pared][\u0027proportion\u0027]\n    ax.bar(\n        positions + i * bar_width, \n        data_estado, \n        bar_width, \n        label\u003destado_pared, \n        color\u003destado_color\n    )\n\n    # Agregar etiquetas a las barras\n    for j in range(len(materiales_pared)):\n        ax.text(\n            positions[j] + i * bar_width, \n            data_estado.iloc[j] + 0.01, \n            f\"{data_estado.iloc[j]:.2f}\", \n            ha\u003d\u0027center\u0027\n        )\n\n# Añadir la leyenda, etiquetas de eje y título\nax.legend(title\u003d\u0027Estado de las paredes\u0027)\nplt.xlabel(\u0027Material de las paredes\u0027)\nplt.ylabel(\u0027Proporción\u0027)\nplt.title(\u0027Proporción de estado de las paredes por material\u0027)\n\n# Posiciones del eje x y etiquetas para cada barra agrupada\nax.set_xticks(positions + (bar_width * len(estados_techo) / 2))\nax.set_xticklabels(materiales_pared)\n\n# Rotar las etiquetas del eje x\nplt.xticks(rotation\u003d-45)\n\n# Mostrar el gráfico\nplt.tight_layout()\nplt.show()\n"
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\n# Lista de estados del techo y materiales únicos\nestados_piso \u003d pdfpiso[\u0027estado_piso\u0027].unique()\nmateriales_piso \u003d pdfpiso[\u0027material_piso\u0027].unique()\n\n# Crear un DataFrame con todas las combinaciones posibles de material_piso y estado_piso\nall_combinations \u003d pd.DataFrame([(m, e) for m in materiales_piso for e in estados_piso], columns\u003d[\u0027material_piso\u0027, \u0027estado_piso\u0027])\n\n# Hacer un merge de los datos originales (pdfpiso) con todas las combinaciones posibles\nmerged_data \u003d pd.merge(all_combinations, pdfpiso, how\u003d\u0027left\u0027, on\u003d[\u0027material_piso\u0027, \u0027estado_piso\u0027])\nmerged_data.fillna(0, inplace\u003dTrue)  # Rellenar los valores NaN con cero\n\n# Crear un gráfico de barras agrupadas con tamaño más grande\nfig, ax \u003d plt.subplots(figsize\u003d(12, 8))  # Ajustar el tamaño aquí\n\n# Diccionario para asignar colores a cada estado del techo\ncolores_dict \u003d {\n    \u0027Malo\u0027: \u0027r\u0027,      # Rojo\n    \u0027Regular\u0027: \u0027c\u0027,   # Amarillo\n    \u0027Bueno\u0027: \u0027g\u0027      # Verde\n}\n\n# Ancho de las barras agrupadas\nbar_width \u003d 0.2\n\n# Posiciones para cada grupo de barras\npositions \u003d np.arange(len(materiales_piso))\n\n# Crear las barras agrupadas y agregar etiquetas\nfor i, estado_piso in enumerate(estados_piso):\n    estado_color \u003d colores_dict.get(estado_piso, \u0027k\u0027)\n    data_estado \u003d merged_data[merged_data[\u0027estado_piso\u0027] \u003d\u003d estado_piso][\u0027proportion\u0027]\n    ax.bar(\n        positions + i * bar_width, \n        data_estado, \n        bar_width, \n        label\u003destado_piso, \n        color\u003destado_color\n    )\n\n    # Agregar etiquetas a las barras\n    for j in range(len(materiales_piso)):\n        ax.text(\n            positions[j] + i * bar_width, \n            data_estado.iloc[j] + 0.01, \n            f\"{data_estado.iloc[j]:.2f}\", \n            ha\u003d\u0027center\u0027\n        )\n\n# Añadir la leyenda, etiquetas de eje y título\nax.legend(title\u003d\u0027Estado del techo\u0027)\nplt.xlabel(\u0027Material del techo\u0027)\nplt.ylabel(\u0027Proporción\u0027)\nplt.title(\u0027Proporción de estado del techo por material\u0027)\n\n# Posiciones del eje x y etiquetas para cada barra agrupada\nax.set_xticks(positions + (bar_width * len(estados_piso) / 2))\nax.set_xticklabels(materiales_piso)\n\n# Rotar las etiquetas del eje x\nplt.xticks(rotation\u003d-45)\n\n# Mostrar el gráfico\nplt.tight_layout()\nplt.show()\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Grafico de dispersion\n***tasa de desempleo - gasto de combustibles***\neste grafico permite identificar comportamiento atipico entre las provincias en relacion son su tasa de desempleo promedio y la relacion que tienen con el gato de combustibel.\nSe encontro que Tungurahua presentan un comportamiento atipo a las demas indicando que a pesar que la tasa de desempleo es alta su gato de combustible tambien lo es a diferencia de las otras.\nEsto podria indicar que tiene potencial para proyectos de inversion orientado a combustibles, ademas se podria deducir que albergan industrias estrategicas para la economia.\nAdemas se infiere que las provincias con un comportamiento inusual al resto podrian ser areas de mayor crecimiento economico."
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%mySQL(saveAs\u003d result2)\n\nSELECT \n    p.nombre_provincia,\n    AVG(p.tasa_desempleo) AS tasa_desempleo_promedio,\n    SUM(hc.gasto_combustible) AS total_gasto_combustible\nFROM\n    provincia p\nJOIN\n    canton c ON p.cod_provincia \u003d c.provincia_canton\nJOIN\n    parroquia pa ON c.cod_canton \u003d pa.cod_canton\nJOIN\n    vivienda v ON pa.cod_parroquia \u003d v.cod_parroquia\nJOIN\n    hogar h ON v.id_vivienda \u003d h.id_vivienda\nJOIN\n    hogar_combustibles hc ON h.id_hogar \u003d hc.id_hogar\nWHERE p.nombre_provincia !\u003d \u0027 Zonas No Delimitadas\u0027 \nGROUP BY\n    p.nombre_provincia;\n\n"
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\ndfdemo2 \u003d z.getAsDataFrame(\u0027result2\u0027)\ntype(dfdemo2)"
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nimport matplotlib.pyplot as plt\n\n# Crear el gráfico de dispersión\nplt.figure(figsize\u003d(10, 6))\nplt.scatter(dfdemo2[\u0027tasa_desempleo_promedio\u0027], dfdemo2[\u0027total_gasto_combustible\u0027])\n\n# Etiquetas y título del gráfico\nplt.xlabel(\"Tasa de Desempleo Promedio\")\nplt.ylabel(\"Gasto en Combustible\")\nplt.title(\"Relación entre Tasa de Desempleo y Gasto en Combustible por Provincia\")\n\n# Etiquetas para cada punto (provincia)\nfor i, row in dfdemo2.iterrows():\n    plt.text(row[\u0027tasa_desempleo_promedio\u0027], row[\u0027total_gasto_combustible\u0027], row[\u0027nombre_provincia\u0027])\n\n# Mostrar el gráfico\nplt.show()\n\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Porcentaje de viviendas con servicios básicos ideales "
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%mySQL(saveAs\u003dresult5)\nSELECT p.nombre_provincia, \n       COUNT(*) AS cantidad_hogares,\n       COUNT(*) * 100.0 / total_hogares_provincia.total AS porcentaje\nFROM provincia p\nINNER JOIN canton c ON p.cod_provincia \u003d c.provincia_canton\nINNER JOIN parroquia pa ON c.cod_canton \u003d pa.cod_canton\nINNER JOIN vivienda v ON pa.cod_parroquia \u003d v.cod_parroquia\nINNER JOIN hogar h ON v.id_vivienda \u003d h.id_vivienda\nINNER JOIN servicios_basicos sb ON h.id_hogar \u003d sb.id_hogar\nINNER JOIN (\n  SELECT p.cod_provincia, COUNT(*) AS total\n  FROM provincia p\n  INNER JOIN canton c ON p.cod_provincia \u003d c.provincia_canton\n  INNER JOIN parroquia pa ON c.cod_canton \u003d pa.cod_canton\n  INNER JOIN vivienda v ON pa.cod_parroquia \u003d v.cod_parroquia\n  INNER JOIN hogar h ON v.id_vivienda \u003d h.id_vivienda\n  INNER JOIN servicios_basicos sb ON h.id_hogar \u003d sb.id_hogar\n  GROUP BY p.cod_provincia\n) AS total_hogares_provincia ON p.cod_provincia \u003d total_hogares_provincia.cod_provincia\nWHERE sb.agua_tuberia \u003d \u0027Por tubería dentro de la vivienda\u0027 AND sb.servicio_higienico \u003d \u0027Excusado y alcantarillado\u0027\nGROUP BY p.nombre_provincia, total_hogares_provincia.total;\n"
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val dfFromMysql5 \u003d z.get(\"result5\")\n"
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val arr \u003d dfFromMysql5.toString.split(\"\\n\")\nval colsName \u003d arr(0).split(\"\\t\")\nval dataArr \u003d arr.drop(1)\nval data \u003d dataArr.map(row\u003d\u003e row.split(\"\\t\")).map(row\u003d\u003e (row(0), row(1), row(2).toDouble))"
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val dfAux \u003d spark\r\n .createDataFrame(data)\r\n .toDF(colsName(0), colsName(1), colsName(2))"
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "dfAux.show"
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val json \u003d dfAux.toJSON.map(row \u003d\u003e row.mkString).collectAsList"
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "z.angularBind(\"dataAsJSON\", json)"
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%angular\r\n\u003cinput type\u003d\"text\" id\u003d\"data4Spark\" value\u003d{{dataAsJSON}}\u003e"
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%angular\n\u003cscript\u003e\nvar cleanText \u003d $(\u0027#data4Spark\u0027).val().replaceAll(\"\\\\\", \"\").replaceAll(\"\\\"{\", \"{\").replaceAll(\"}\\\"\",\n\"}\");\nconsole.log(cleanText);\n$(\u0027#data4Spark\u0027).val(cleanText);\n\u003c/script\u003e"
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%angular\n\u003cstyle\u003e\n#chartdiv2 {\n    width: 100%;\n    height: 500px;\n}\n\u003c/style\u003e\n\n\u003c!-- Resources --\u003e\n\u003cscript src\u003d\"https://cdn.amcharts.com/lib/5/index.js\"\u003e\u003c/script\u003e\n\u003cscript src\u003d\"https://cdn.amcharts.com/lib/5/xy.js\"\u003e\u003c/script\u003e\n\u003cscript src\u003d\"https://cdn.amcharts.com/lib/5/themes/Animated.js\"\u003e\u003c/script\u003e\n\n\u003c!-- Chart code --\u003e\n\u003cscript\u003e\n\n// Leer los datos desde el input (No necesita cambio) y transformarlos a JSON\nvar data \u003d JSON.parse($(\u0027#data4Spark\u0027).val());\nconsole.log(data);\nam5.ready(function() {\n// Create root element\n// https://www.amcharts.com/docs/v5/getting-started/#Root_element\nvar root \u003d am5.Root.new(\"chartdiv\");\n// Set themes\n// https://www.amcharts.com/docs/v5/concepts/themes/\nroot.setThemes([\nam5themes_Animated.new(root)\n]);\n// Create chart\n// https://www.amcharts.com/docs/v5/charts/xy-chart/\nvar chart \u003d root.container.children.push(am5xy.XYChart.new(root, {\npanX: false,\npanY: false,\nwheelX: \"panX\",\nwheelY: \"zoomX\",\nlayout: root.verticalLayout\n}));\n// Add legend\n// https://www.amcharts.com/docs/v5/charts/xy-chart/legend-xy-series/\nvar legend \u003d chart.children.push(\nam5.Legend.new(root, {\ncenterX: am5.p50,\nx: am5.p50,\nposition: \u0027top\u0027\n})\n);\n// Create axes\n// https://www.amcharts.com/docs/v5/charts/xy-chart/axes/\nvar xRenderer \u003d am5xy.AxisRendererX.new(root, {\ncellStartLocation: 0.1,\ncellEndLocation: 0.9\n})\nvar xAxis \u003d chart.xAxes.push(am5xy.CategoryAxis.new(root, {\ncategoryField: \"nombre_provincia\", //Cambiar por su columna de agrupamiento\nrenderer: xRenderer,\ntooltip: am5.Tooltip.new(root, {})\n}));\nxRenderer.grid.template.setAll({\nlocation: 1\n})\nxAxis.data.setAll(data);\nvar yAxis \u003d chart.yAxes.push(am5xy.ValueAxis.new(root, {\nrenderer: am5xy.AxisRendererY.new(root, {\nstrokeOpacity: 0.1\n})\n}));\n// Add series\n// https://www.amcharts.com/docs/v5/charts/xy-chart/series/\nfunction makeSeries(name, fieldName) {\nvar series \u003d chart.series.push(am5xy.ColumnSeries.new(root, {\nname: name,\nxAxis: xAxis,\nyAxis: yAxis,\nvalueYField: fieldName,\ncategoryXField: \"nombre_provincia\" //Cambiar por su columna de agrupamiento\n}));\nseries.columns.template.setAll({\ntooltipText: \"{name}, {categoryX}:{valueY.formatNumber(\u0027###.##\u0027)}\",\nwidth: am5.percent(90),\ntooltipY: 0,\nstrokeOpacity: 0\n});\nseries.data.setAll(data);\n// Make stuff animate on load\n// https://www.amcharts.com/docs/v5/concepts/animations/\nseries.appear();\nseries.bullets.push(function() {\nreturn am5.Bullet.new(root, {\nlocationY: 0,\nsprite: am5.Label.new(root, {\ntext: \"{valueY}\",\nfill: root.interfaceColors.get(\"alternativeText\"),\ncenterY: 0,\ncenterX: am5.p50,\npopulateText: true\n})\n});\n});\nlegend.data.push(series);\n}\n//Necesita adaptar para el resto de sus columnas, una llamada a makeSeries por cada columna\n//En makeSeries, el primer parámetro es el valor a mostrar y el segundo es el nombre de\n//la columna o propiedad JSON\n//makeSeries(\"cantidad_hogares\", \"cantidad_hogares\");\nmakeSeries(\"porcentaje\", \"porcentaje\");\n// Make stuff animate on load\n//https://www.amcharts.com/docs/v5/concepts/animations/\nchart.appear(1000, 100);\n}); // end am5.ready()\n\u003c/script\u003e\n\u003c!-- HTML --\u003e\n\u003cdiv id\u003d\"chartdiv\"\u003e\u003c/div\u003e\n"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "format": "text/plain"
      },
      "source": "%angular\n"
    }
  ]
}